{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPeLK8HW3mm+OgBfH+Oe/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c6444e06eb2433fb0f01d57b483cd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e10802f859ef4aff80ee19964b1bb60c",
              "IPY_MODEL_80a1a502e12a4b2b9fcaec9d23ac7fec",
              "IPY_MODEL_8ca28b2c5d424f9b95ed8e3a63e20bb6"
            ],
            "layout": "IPY_MODEL_237b78ed5c264b86bacae5003c6b3033"
          }
        },
        "e10802f859ef4aff80ee19964b1bb60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a48967bcae4650959badf7a4f05a53",
            "placeholder": "​",
            "style": "IPY_MODEL_77a643b8ddfe47cfaf242d0bdc338d52",
            "value": "Downloading data: 100%"
          }
        },
        "80a1a502e12a4b2b9fcaec9d23ac7fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_220bfe2fe648425bbe66d5ffa6f807cd",
            "max": 1179510242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9a4f4cc3e88411b86396867698ea9b7",
            "value": 1179510242
          }
        },
        "8ca28b2c5d424f9b95ed8e3a63e20bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_168962d377e54abfbc0a69d17fddd9bf",
            "placeholder": "​",
            "style": "IPY_MODEL_329b6eaf54d54f3ca8ae5053bedf8d23",
            "value": " 1.18G/1.18G [00:12&lt;00:00, 182MB/s]"
          }
        },
        "237b78ed5c264b86bacae5003c6b3033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a48967bcae4650959badf7a4f05a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a643b8ddfe47cfaf242d0bdc338d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "220bfe2fe648425bbe66d5ffa6f807cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a4f4cc3e88411b86396867698ea9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "168962d377e54abfbc0a69d17fddd9bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "329b6eaf54d54f3ca8ae5053bedf8d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24e10fed7c7244e29a81e93ff967db2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ee00cf627034f60b6fcf3852983edc9",
              "IPY_MODEL_dd4e6888c61544c59ee8e46ac5a59b9b",
              "IPY_MODEL_dfe6d5422bcc4a639a418b0c591620f7"
            ],
            "layout": "IPY_MODEL_ee116e21b0804b1b90158e2a68a55e06"
          }
        },
        "9ee00cf627034f60b6fcf3852983edc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42c227bf0bc44f084204a859f3bd2ee",
            "placeholder": "​",
            "style": "IPY_MODEL_facc2e151d3b48899fa62d27547cc4b2",
            "value": "Generating train split: 100%"
          }
        },
        "dd4e6888c61544c59ee8e46ac5a59b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d337c6b6ca064bedb36d65d12bf26820",
            "max": 74004228,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d80c1fbe24d4fccb6e4c6f1758711d6",
            "value": 74004228
          }
        },
        "dfe6d5422bcc4a639a418b0c591620f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89559ae235c4452cb635d7799fec9c87",
            "placeholder": "​",
            "style": "IPY_MODEL_20e8caceaea54618a10e9549e864861b",
            "value": " 74004228/74004228 [33:30&lt;00:00, 21998.46 examples/s]"
          }
        },
        "ee116e21b0804b1b90158e2a68a55e06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42c227bf0bc44f084204a859f3bd2ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "facc2e151d3b48899fa62d27547cc4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d337c6b6ca064bedb36d65d12bf26820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d80c1fbe24d4fccb6e4c6f1758711d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89559ae235c4452cb635d7799fec9c87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e8caceaea54618a10e9549e864861b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47402c9f103945e79d138d6db77b4dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ce74d1b09af4c97b33ef81ddc613d65",
              "IPY_MODEL_552d84d7e0464cd2b5865e8b36a1e286",
              "IPY_MODEL_6d9df86a88ac4dc4ae54d29c610dc269"
            ],
            "layout": "IPY_MODEL_c9785044f3a8490f8159441b53af59c5"
          }
        },
        "1ce74d1b09af4c97b33ef81ddc613d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d5a98e1d1b4ab8a3491968e7fbf4b1",
            "placeholder": "​",
            "style": "IPY_MODEL_4a7fa8c48bc945abb156042c03405818",
            "value": ""
          }
        },
        "552d84d7e0464cd2b5865e8b36a1e286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94c8afcb9d8f4caeac55e2e35d182df0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3388158cce549afb80e604f26c65b44",
            "value": 0
          }
        },
        "6d9df86a88ac4dc4ae54d29c610dc269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1f1a064c9824f9d91766f8b15530b0b",
            "placeholder": "​",
            "style": "IPY_MODEL_45a4274950f6470da2e959a4eeb91038",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "c9785044f3a8490f8159441b53af59c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d5a98e1d1b4ab8a3491968e7fbf4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a7fa8c48bc945abb156042c03405818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94c8afcb9d8f4caeac55e2e35d182df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b3388158cce549afb80e604f26c65b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1f1a064c9824f9d91766f8b15530b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a4274950f6470da2e959a4eeb91038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhatsingh/hugging-face-learning/blob/main/Wk2_Tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENIZATION\n",
        "This module covers how to tokenize a simple dataset into a form that is understandable by an LLM model (basically a list of numbers).\n",
        "\n",
        "Notebook average execution time: 33min + 25min + 25min = 1hr 23mins"
      ],
      "metadata": {
        "id": "xnnpYnVfsl9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Tokenizers Package"
      ],
      "metadata": {
        "id": "RDQu4jBDUrwd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kU-WCGBzpdll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "6c6444e06eb2433fb0f01d57b483cd89",
            "e10802f859ef4aff80ee19964b1bb60c",
            "80a1a502e12a4b2b9fcaec9d23ac7fec",
            "8ca28b2c5d424f9b95ed8e3a63e20bb6",
            "237b78ed5c264b86bacae5003c6b3033",
            "b9a48967bcae4650959badf7a4f05a53",
            "77a643b8ddfe47cfaf242d0bdc338d52",
            "220bfe2fe648425bbe66d5ffa6f807cd",
            "e9a4f4cc3e88411b86396867698ea9b7",
            "168962d377e54abfbc0a69d17fddd9bf",
            "329b6eaf54d54f3ca8ae5053bedf8d23",
            "24e10fed7c7244e29a81e93ff967db2f",
            "9ee00cf627034f60b6fcf3852983edc9",
            "dd4e6888c61544c59ee8e46ac5a59b9b",
            "dfe6d5422bcc4a639a418b0c591620f7",
            "ee116e21b0804b1b90158e2a68a55e06",
            "b42c227bf0bc44f084204a859f3bd2ee",
            "facc2e151d3b48899fa62d27547cc4b2",
            "d337c6b6ca064bedb36d65d12bf26820",
            "6d80c1fbe24d4fccb6e4c6f1758711d6",
            "89559ae235c4452cb635d7799fec9c87",
            "20e8caceaea54618a10e9549e864861b"
          ]
        },
        "outputId": "01828714-659d-4fee-c8ce-c661cd796ea0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c6444e06eb2433fb0f01d57b483cd89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/74004228 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24e10fed7c7244e29a81e93ff967db2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 74004228\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers datasets &> /dev/null\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "ds = load_dataset('bookcorpus', split='all', trust_remote_code=True)\n",
        "pprint(ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the dataset is loaded correctly and look at the initial few lines\n",
        "num_samples = 5\n",
        "for idx, sample in enumerate(ds[0:num_samples]['text']):\n",
        "  print(f'{idx} : {sample}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo555B_8UwuJ",
        "outputId": "c52ececb-ded7-402f-94fb-f23a11cfa6c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 : usually , he would be tearing around the living room , playing with his toys .\n",
            "1 : but just one look at a minion sent him practically catatonic .\n",
            "2 : that had been megan 's plan when she got him dressed earlier .\n",
            "3 : he 'd seen the movie almost by mistake , considering he was a little young for the pg cartoon , but with older cousins , along with her brothers , mason was often exposed to things that were older .\n",
            "4 : she liked to think being surrounded by adults and older kids was one reason why he was a such a good talker for his age .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usual steps followed in any tokenization:\n",
        "\n",
        "Input Text $→$ Normalization $→$ Pre-Tokenizer $→$ Algorithm (model) $→$ PostProcessing $→$ Output tokens\n",
        "\n",
        "**Example:**<br>\n",
        "1. **Input Text**: Simple text, stored as a List of Sentences, to be passed to the model.\n",
        "2. **Normalization**: To convert the text to a standard form (example: to convert everything to lowercase or to remove accent marks in languages, etc)\n",
        "3. **Pre-Tokenizer**: A basic algorithm (like explode sentences from \" \" character) to make an initial token list.\n",
        "4. **Algorithm**: An algorithm (like Byte-Pair, Word-Piece, Sentence-Piece, etc etc) that will convert the given pre-trained token set to a more **useful** tokens.\n",
        "5. **PostProcessing**: This includes adding special tokens like \"[SEP]\" or \"[PAD]\" etc etc.\n",
        "6. **Output tokens**: A list of tokens that can be passed to the model to train on!"
      ],
      "metadata": {
        "id": "8sLeG9tzU3LZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some useful Tokenizer methods:\n",
        "1. `add_special_tokens(str, AddedToken)`\n",
        "2. `add_tokens()`\n",
        "3. `enable_padding()` and `enable_truncation()`\n",
        "4. `encode(seq, pair, is_pretokenized)` and `encode_batch()`\n",
        "5. `decode()` and `decode_batch()`\n",
        "6. `from_file(.json)` for local json file\n",
        "7. `from_pretrained(.json)` to import from hub\n",
        "8. `get_vocab()` and `get_vocab_size()`\n",
        "9. `id_to_token()` and `token_to_id()`\n",
        "10. `post_process()`\n",
        "11. `train(files)` and `train_from_iterator(dataset)`"
      ],
      "metadata": {
        "id": "_gu0meJxatgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.normalizers import Lowercase\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.models import BPE\n",
        "\n",
        "model = BPE(unk_token=\"[UNK]\")\n",
        "tokenizer = Tokenizer(model)\n",
        "\n",
        "tokenizer.normalizer = Lowercase()\n",
        "tokenizer.pre_tokenizer = Whitespace()"
      ],
      "metadata": {
        "id": "pXDhgb9HWjT4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer\n",
        "\n",
        "We have passed the required information to initialize the tokenizer. Now we need to train the tokenizer (i.e. run the above sets in order on the train dataset) so that we can get our desired output tokens.\n",
        "\n",
        "Assuming that we want output token vocabulary size to be of 32k, we run the following code"
      ],
      "metadata": {
        "id": "-kf7U5eXW2qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.trainers import BpeTrainer\n",
        "\n",
        "trainer = BpeTrainer(vocab_size=32000,\n",
        "                     special_tokens=['[PAD]', '[UNK]'],\n",
        "                     continuing_subword_prefix=\"##\"\n",
        "                     )"
      ],
      "metadata": {
        "id": "SHQwleGlX87A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For batch processing, create a function that will give out dataset in batches"
      ],
      "metadata": {
        "id": "_54-RWasb4MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(batch_size=1000):\n",
        "  for i in range(0, len(ds), batch_size):\n",
        "    yield ds[i: i+batch_size]['text']"
      ],
      "metadata": {
        "id": "6fMQHPitbouH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the tokenizer from the data"
      ],
      "metadata": {
        "id": "MHBaqsEpcuJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.train_from_iterator(\n",
        "      iterator = get_batch(batch_size=10000),\n",
        "      trainer = trainer,\n",
        "      length = len(ds)\n",
        "    )"
      ],
      "metadata": {
        "id": "2wH6EgNJcH2F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save the trained model to disk\n",
        "\n",
        "This function will only save the model to the disk i.e. the vocubulary. No extra information (like attention masks, special tokens list, etc etc) are stored to the disk. For that, look at the sections ahead.\n",
        "\n",
        "`model` is the directory name, `hopper` is the file-prefix for the files which will be saved into this directory."
      ],
      "metadata": {
        "id": "HeaomNbEc1RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model.save('model', prefix='hopper')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH9F9gnbc38Q",
        "outputId": "e78e0e71-c159-492a-c2fa-ddcef563a9da"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model/hopper-vocab.json', 'model/hopper-merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The trained vocabulary\n",
        "\n",
        "Get the trained vocabulary."
      ],
      "metadata": {
        "id": "lQ3hhnNHdJ6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "# vocab_sorted = sorted(vocab.items(), key = lambda item: item[1])"
      ],
      "metadata": {
        "id": "r4lxACwydS3a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding\n",
        "\n",
        "Now that we have found our vocabulary, let us try to encode some sample english texts into our own learnt vocabulary."
      ],
      "metadata": {
        "id": "uEW8M7JneNnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = ds[0]['text']\n",
        "print(f'Sample: {sample}')\n",
        "\n",
        "encoding = tokenizer.encode(sample)\n",
        "print(encoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJBO9NR-eWRD",
        "outputId": "373514ff-dc8e-4324-898c-28405f0c4e93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: usually , he would be tearing around the living room , playing with his toys .\n",
            "Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any encoding will contain the following useful attributes:\n",
        "\n",
        "1. `token_ids` indicating the actual encoding value that is passed to an ML algorithm.\n",
        "\n",
        "2. `tokens` stores the actual tokens from the vocabulary that makes up the sentence.\n",
        "\n",
        "3. `type_ids` used for advanced models like BERT. Google it if you wanna know more.\n",
        "\n",
        "4. `attention_mask` a list of values containing 0s and 1s, telling the LLM model to pay attention to which word in the text, and which to ignore. For example, if we have added padding to the text, padding's attention will be 0, as it does not add value for us."
      ],
      "metadata": {
        "id": "WHj0bQ_CeqBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "token_ids = encoding.ids\n",
        "tokens = encoding.tokens\n",
        "type_ids = encoding.type_ids\n",
        "attention_mask = encoding.attention_mask\n",
        "\n",
        "out_dict = {'tokens': tokens, \"ids\": token_ids, \"type_ids\": type_ids, \"attention_mask\": attention_mask}\n",
        "df = pd.DataFrame.from_dict(out_dict)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "0HZbHFVNfeB2",
        "outputId": "88d83b93-6280-4703-e81f-bfed55254fa4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     tokens   ids  type_ids  attention_mask\n",
              "0   usually  2462         0               1\n",
              "1         ,    19         0               1\n",
              "2        he   149         0               1\n",
              "3     would   277         0               1\n",
              "4        be   162         0               1\n",
              "5   tearing  6456         0               1\n",
              "6    around   422         0               1\n",
              "7       the   131         0               1\n",
              "8    living  1559         0               1\n",
              "9      room   536         0               1\n",
              "10        ,    19         0               1\n",
              "11  playing  2301         0               1\n",
              "12     with   201         0               1\n",
              "13      his   177         0               1\n",
              "14     toys  9774         0               1\n",
              "15        .    21         0               1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf1da3a8-3824-4c31-b884-e18b5db2f49c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>ids</th>\n",
              "      <th>type_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>usually</td>\n",
              "      <td>2462</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>,</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>would</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>be</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tearing</td>\n",
              "      <td>6456</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>around</td>\n",
              "      <td>422</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>living</td>\n",
              "      <td>1559</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>room</td>\n",
              "      <td>536</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>,</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>playing</td>\n",
              "      <td>2301</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>with</td>\n",
              "      <td>201</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>his</td>\n",
              "      <td>177</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>toys</td>\n",
              "      <td>9774</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>.</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf1da3a8-3824-4c31-b884-e18b5db2f49c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf1da3a8-3824-4c31-b884-e18b5db2f49c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf1da3a8-3824-4c31-b884-e18b5db2f49c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4cc696e1-4682-401e-b4b9-d8d968c15925\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4cc696e1-4682-401e-b4b9-d8d968c15925')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4cc696e1-4682-401e-b4b9-d8d968c15925 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_76fe5d8c-bf3d-45e3-bd86-4940ac6e29f2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_76fe5d8c-bf3d-45e3-bd86-4940ac6e29f2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"room\",\n          \"with\",\n          \"usually\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2752,\n        \"min\": 19,\n        \"max\": 9774,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          536,\n          201,\n          2462\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type_ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vizualize the encoded sentence\n",
        "\n",
        "Let us visualize the sentence in the form of tokens encoded."
      ],
      "metadata": {
        "id": "BbXidwAifvJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.tools import EncodingVisualizer\n",
        "vs = EncodingVisualizer(tokenizer=tokenizer)\n",
        "vs(text=sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "Hgfw_pUDf21I",
        "outputId": "5fbf0873-a1ed-48c4-eacc-be276b9cc88b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <html>\n",
              "        <head>\n",
              "            <style>\n",
              "                .tokenized-text {\n",
              "    width:100%;\n",
              "    padding:2rem;\n",
              "    max-height: 400px;\n",
              "    overflow-y: auto;\n",
              "    box-sizing:border-box;\n",
              "    line-height:4rem; /* Lots of space between lines */\n",
              "    font-family: \"Roboto Light\", \"Ubuntu Light\", \"Ubuntu\", monospace;\n",
              "    box-shadow: 2px 2px 2px rgba(0,0,0,0.2);\n",
              "    background-color: rgba(0,0,0,0.01);\n",
              "    letter-spacing:2px; /* Give some extra separation between chars */\n",
              "}\n",
              ".non-token{\n",
              "    /* White space and other things the tokenizer ignores*/\n",
              "    white-space: pre;\n",
              "    letter-spacing:4px;\n",
              "    border-top:1px solid #A0A0A0; /* A gentle border on top and bottom makes tabs more ovious*/\n",
              "    border-bottom:1px solid #A0A0A0;\n",
              "    line-height: 1rem;\n",
              "    height: calc(100% - 2px);\n",
              "}\n",
              "\n",
              ".token {\n",
              "    white-space: pre;\n",
              "    position:relative;\n",
              "    color:black;\n",
              "    letter-spacing:2px;\n",
              "}\n",
              "\n",
              ".annotation{\n",
              "    white-space:nowrap; /* Important - ensures that annotations appears even if the annotated text wraps a line */\n",
              "    border-radius:4px;\n",
              "    position:relative;\n",
              "    width:fit-content;\n",
              "}\n",
              ".annotation:before {\n",
              "    /*The before holds the text and the after holds the background*/\n",
              "    z-index:1000; /* Make sure this is above the background */\n",
              "    content:attr(data-label); /* The annotations label is on a data attribute */\n",
              "    color:white;\n",
              "    position:absolute;\n",
              "    font-size:1rem;\n",
              "    text-align:center;\n",
              "    font-weight:bold;\n",
              "\n",
              "    top:1.75rem;\n",
              "    line-height:0;\n",
              "    left:0;\n",
              "    width:100%;\n",
              "    padding:0.5rem 0;\n",
              "    /* These make it so an annotation doesn't stretch beyond the annotated text if the label is longer*/\n",
              "    overflow: hidden;\n",
              "    white-space: nowrap;\n",
              "    text-overflow:ellipsis;\n",
              "}\n",
              "\n",
              ".annotation:after {\n",
              "    content:attr(data-label); /* The content defines the width of the annotation*/\n",
              "    position:absolute;\n",
              "    font-size:0.75rem;\n",
              "    text-align:center;\n",
              "    font-weight:bold;\n",
              "    text-overflow:ellipsis;\n",
              "    top:1.75rem;\n",
              "    line-height:0;\n",
              "    overflow: hidden;\n",
              "    white-space: nowrap;\n",
              "\n",
              "    left:0;\n",
              "    width:100%; /* 100% of the parent, which is the annotation whose width is the tokens inside it*/\n",
              "\n",
              "    padding:0.5rem 0;\n",
              "    /* Nast hack below:\n",
              "    We set the annotations color in code because we don't know the colors at css time.\n",
              "    But you can't pass a color as a data attribute to get it into the pseudo element (this thing)\n",
              "    So to get around that, annotations have the color set on them with a style attribute and then we\n",
              "    can get the color with currentColor.\n",
              "    Annotations wrap tokens and tokens set the color back to black\n",
              "     */\n",
              "    background-color: currentColor;\n",
              "}\n",
              ".annotation:hover::after, .annotation:hover::before{\n",
              "    /* When the user hovers over an annotation expand the label to display in full\n",
              "     */\n",
              "    min-width: fit-content;\n",
              "}\n",
              "\n",
              ".annotation:hover{\n",
              "    /* Emphasize the annotation start end with a border on hover*/\n",
              "    border-color: currentColor;\n",
              "    border: 2px solid;\n",
              "}\n",
              ".special-token:not(:empty){\n",
              "    /*\n",
              "    A none empty special token is like UNK (as opposed to CLS which has no representation in the text )\n",
              "     */\n",
              "    position:relative;\n",
              "}\n",
              ".special-token:empty::before{\n",
              "    /* Special tokens that don't have text are displayed as pseudo elements so we dont select them with the mouse*/\n",
              "    content:attr(data-stok);\n",
              "    background:#202020;\n",
              "    font-size:0.75rem;\n",
              "    color:white;\n",
              "    margin: 0 0.25rem;\n",
              "    padding: 0.25rem;\n",
              "    border-radius:4px\n",
              "}\n",
              "\n",
              ".special-token:not(:empty):before {\n",
              "    /* Special tokens that have text (UNK) are displayed above the actual text*/\n",
              "    content:attr(data-stok);\n",
              "    position:absolute;\n",
              "    bottom:1.75rem;\n",
              "    min-width:100%;\n",
              "    width:100%;\n",
              "    height:1rem;\n",
              "    line-height:1rem;\n",
              "    font-size:1rem;\n",
              "    text-align:center;\n",
              "    color:white;\n",
              "    font-weight:bold;\n",
              "    background:#202020;\n",
              "    border-radius:10%;\n",
              "}\n",
              "/*\n",
              "We want to alternate the color of tokens, but we can't use nth child because tokens might be broken up by annotations\n",
              "instead we apply even and odd class at generation time and color them that way\n",
              " */\n",
              ".even-token{\n",
              "    background:#DCDCDC\t;\n",
              "    border: 1px solid #DCDCDC;\n",
              "}\n",
              ".odd-token{\n",
              "    background:#A0A0A0;\n",
              "    border: 1px solid #A0A0A0;\n",
              "}\n",
              ".even-token.multi-token,.odd-token.multi-token{\n",
              "    background:  repeating-linear-gradient(\n",
              "    45deg,\n",
              "    transparent,\n",
              "    transparent 1px,\n",
              "    #ccc 1px,\n",
              "    #ccc 1px\n",
              "    ),\n",
              "    /* on \"bottom\" */\n",
              "    linear-gradient(\n",
              "    to bottom,\n",
              "    #FFB6C1,\n",
              "    #999\n",
              "    );\n",
              "}\n",
              "\n",
              ".multi-token:hover::after {\n",
              "    content:\"This char has more than 1 token\"; /* The content defines the width of the annotation*/\n",
              "    color:white;\n",
              "    background-color: black;\n",
              "    position:absolute;\n",
              "    font-size:0.75rem;\n",
              "    text-align:center;\n",
              "    font-weight:bold;\n",
              "    text-overflow:ellipsis;\n",
              "    top:1.75rem;\n",
              "    line-height:0;\n",
              "    overflow: hidden;\n",
              "    white-space: nowrap;\n",
              "    left:0;\n",
              "    width:fit-content; /* 100% of the parent, which is the annotation whose width is the tokens inside it*/\n",
              "    padding:0.5rem 0;\n",
              "}\n",
              "\n",
              "            </style>\n",
              "        </head>\n",
              "        <body>\n",
              "            <div class=\"tokenized-text\" dir=auto>\n",
              "            <span class=\"token even-token\"  >usually</span><span class=\"non-token\"  > </span><span class=\"token odd-token\"  >,</span><span class=\"non-token\"  > </span><span class=\"token even-token\"  >he</span><span class=\"non-token\"  > </span><span class=\"token odd-token\"  >would</span><span class=\"non-token\"  > </span><span class=\"token even-token\"  >be</span><span class=\"non-token\"  > </span><span class=\"token odd-token\"  >tearing</span><span class=\"non-token\"  > </span><span class=\"token even-token\"  >around</span><span class=\"non-token\"  > </span><span class=\"token odd-token\"  >the</span><span class=\"non-token\"  > </span><span class=\"token even-token\"  >living</span><span class=\"non-token\"  > </span><span class=\"token odd-token\"  >room</span><span class=\"non-token\"  > </span><span class=\"token even-token\"  >,</span><span class=\"non-token\"  > </span><span class=\"token odd-token\"  >playing</span><span class=\"non-token\"  > </span><span class=\"token even-token\"  >with</span><span class=\"non-token\"  > </span><span class=\"token odd-token\"  >his</span><span class=\"non-token\"  > </span><span class=\"token even-token\"  >toys</span><span class=\"non-token\"  > </span><span class=\"token odd-token\"  >.</span>\n",
              "            </div>\n",
              "        </body>\n",
              "    </html>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding and Batch encoding\n",
        "\n",
        "When there are a lot of sentences, we need to encode them, as well as add padding to make them of equal lengths. We use the following methods for that:"
      ],
      "metadata": {
        "id": "AExpw9ytgoH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = ds[0:4][\"text\"]\n",
        "\n",
        "batch_encoding = tokenizer.encode_batch(samples)\n",
        "pprint(batch_encoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3uaHEUSgzYh",
        "outputId": "44e16012-1128-4d28-8fd4-b08654086f1d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
            " Encoding(num_tokens=14, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
            " Encoding(num_tokens=14, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
            " Encoding(num_tokens=42, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that there is no padding added to the above sentences, as the length of encodings are different for each sentence. Let us add padding now.\n",
        "\n",
        "We have assumed that our context window size is 512, so we have truncated the sentences to maximum of 512 size."
      ],
      "metadata": {
        "id": "X4rzhiXzhAqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.enable_padding(direction='right',\n",
        "                         pad_id=0,\n",
        "                         pad_type_id=0,\n",
        "                         pad_token = '[PAD]',\n",
        "                         length = None, # if we have a specific context window size, we can put it here, otherwise, it defaults to the max(lengths of the sentences in the sample).\n",
        "                         pad_to_multiple_of = None\n",
        "                         )\n",
        "\n",
        "# maximum size a sentence can have. Padding only adds to the sentence, to delete tokens which exceed the context_window size, use truncate.\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "metadata": {
        "id": "3X0OD0wOhIbs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_encoding = tokenizer.encode_batch(samples)\n",
        "pprint(batch_encoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6LzZ7ysipB3",
        "outputId": "75134899-4b72-4f3b-b4b3-d0cf9f2b839b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Encoding(num_tokens=42, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
            " Encoding(num_tokens=42, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
            " Encoding(num_tokens=42, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
            " Encoding(num_tokens=42, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now observe that the length of the encoding is same for all sentences, which is equal to the max(length of sentences in the batch)=42."
      ],
      "metadata": {
        "id": "viNda6K1t-FE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save everthing to disk\n",
        "\n",
        "Earlier we saved only the model i.e. the vocabulary generated. This will save all the parameters in a tokenizer like `added_tokens`, `model` and its details, `normalizer`, `pre_tokenizer` etc etc."
      ],
      "metadata": {
        "id": "vnryUARaivy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save('hopper.json')"
      ],
      "metadata": {
        "id": "9ty80kfuix3k"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('hopper.json', 'r') as file:\n",
        "  json_data = json.load(file)\n",
        "\n",
        "pprint(json_data, depth=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA13kuuEjK4k",
        "outputId": "7d956341-efa0-426b-accd-f36a6e0d3505"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'added_tokens': [...],\n",
            " 'decoder': None,\n",
            " 'model': {...},\n",
            " 'normalizer': {...},\n",
            " 'padding': {...},\n",
            " 'post_processor': None,\n",
            " 'pre_tokenizer': {...},\n",
            " 'truncation': {...},\n",
            " 'version': '1.0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the saved tokenizer from the disk\n",
        "\n",
        "Use the `from_file()` method of the Tokenizer class."
      ],
      "metadata": {
        "id": "9Vi1Sc4_jagJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the tokenizer class with the algorithm\n",
        "trained_tokenizer = Tokenizer(BPE())\n",
        "trained_tokenizer = trained_tokenizer.from_file('hopper.json')"
      ],
      "metadata": {
        "id": "2H_Pu5bvjczM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if it has worked"
      ],
      "metadata": {
        "id": "axh-v5Suj7nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ds[0]['text']\n",
        "tokens = trained_tokenizer.encode(text).tokens\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxF9tVyFj9f2",
        "outputId": "17eb32ba-9e80-43f6-bc55-77023ae2e07a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT-Like Tokenizers\n",
        "\n",
        "Let us build a bert-like tokenizer.\n",
        "It adds `[CLS]` and `[SEP]` special tokens between sentences."
      ],
      "metadata": {
        "id": "RhYc5K1jkNEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = Tokenizer(BPE(unk_token='[UNK]'))\n",
        "bert_tokenizer.normalizer = Lowercase()\n",
        "bert_tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "bert_trainer = BpeTrainer(vocab_size=32000,\n",
        "                          special_tokens = ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]'],\n",
        "                          continuing_subword_prefix='##'\n",
        "                          )"
      ],
      "metadata": {
        "id": "l4wtvF5SkeeU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up to this point, everything is same as before except the fact that we have added some special tokens to our vocabulary.\n",
        "\n",
        "Let us now define how these tokens are to be added to the sentences. We just need to define the post_processor of our Tokenizer class."
      ],
      "metadata": {
        "id": "IvycriselOZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.processors import TemplateProcessing\n",
        "\n",
        "bert_tokenizer.post_processor = TemplateProcessing(single = \"[CLS] $0 [SEP]\",\n",
        "                                                   pair = \"[CLS] $A [SEP] $B:1\",\n",
        "                                                   special_tokens = [\n",
        "                                                       ('[CLS]', 2),\n",
        "                                                       ('[SEP]', 3)\n",
        "                                                   ]\n",
        "                                                   )"
      ],
      "metadata": {
        "id": "bq-d02wdla-B"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the BERT Model"
      ],
      "metadata": {
        "id": "elHeeSfrmP5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer.train_from_iterator(\n",
        "    get_batch(batch_size=10000),\n",
        "    trainer = bert_trainer,\n",
        "    length = len(ds)\n",
        "  )"
      ],
      "metadata": {
        "id": "FVjELXYRmCDZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### See the Encoding\n",
        "\n",
        "First, let us encode a single sentence:"
      ],
      "metadata": {
        "id": "QQyx5QoTmsss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"All these are so simple to do in HF. Let's do more\"\n",
        "encoded = bert_tokenizer.encode(text)\n",
        "\n",
        "tokens = encoded.tokens\n",
        "ids = encoded.ids\n",
        "out_dict = {'tokens': tokens, 'ids': ids}\n",
        "pprint(out_dict, depth=2, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRTk3HSGmSWO",
        "outputId": "3cfe5a4d-0dff-4085-9a75-5aa2491c2af5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [2, 270, 956, 336, 231, 2534, 141, 206, 157, 56, 98, 24, 462, 17, 67,\n",
            "         206, 387, 3],\n",
            " 'tokens': ['[CLS]', 'all', 'these', 'are', 'so', 'simple', 'to', 'do', 'in',\n",
            "            'h', '##f', '.', 'let', \"'\", 's', 'do', 'more', '[SEP]']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pair of sentences:"
      ],
      "metadata": {
        "id": "ulIcyjhBm0-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"All these are so simple to do in HF. Let's do more\"\n",
        "pair = \"We have a long way to go!\"\n",
        "encoded = bert_tokenizer.encode(text, pair)\n",
        "\n",
        "tokens = encoded.tokens\n",
        "ids = encoded.ids\n",
        "out_dict = {'tokens': tokens, 'ids': ids}\n",
        "pprint(out_dict, depth=2, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN4cgzVEm3D9",
        "outputId": "93a51615-9b77-49fd-fdce-a2b0a93b8729"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [2, 270, 956, 336, 231, 2534, 141, 206, 157, 56, 98, 24, 462, 17, 67,\n",
            "         206, 387, 3, 214, 250, 49, 490, 415, 141, 260, 12],\n",
            " 'tokens': ['[CLS]', 'all', 'these', 'are', 'so', 'simple', 'to', 'do', 'in',\n",
            "            'h', '##f', '.', 'let', \"'\", 's', 'do', 'more', '[SEP]', 'we',\n",
            "            'have', 'a', 'long', 'way', 'to', 'go', '!']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoding\n",
        "\n",
        "After our LLM gives out an output in the form of token_ids, we need to convert those ids back to sentences. Here we need a decoder.\n",
        "\n",
        "The special tokens need to be removed, and the sub-words have to be merged before outputting the final result to the end user."
      ],
      "metadata": {
        "id": "AyjJNzW9nHJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plain_tokens = bert_tokenizer.decode(ids)\n",
        "print(plain_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNYQnPFZnXJt",
        "outputId": "5b1f9530-6eda-4de9-fed3-918d5f4a4658"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all these are so simple to do in h ##f . let ' s do more we have a long way to go !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we see that the special characters are removed, but the words are not merged together still!\n",
        "\n",
        "We have to use a decoding algorithm for this:"
      ],
      "metadata": {
        "id": "d7eTHqE_nhuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.decoders import WordPiece\n",
        "\n",
        "bert_tokenizer.decoder = WordPiece(prefix = \"##\")\n",
        "\n",
        "plain_tokens = bert_tokenizer.decode(ids)\n",
        "print(plain_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNmFls1IojKq",
        "outputId": "b04e7cbf-2bb7-4cef-a4e7-dcf819daaca1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all these are so simple to do in hf. let ' s do more we have a long way to go!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Trained Tokenizer Wrapper\n",
        "\n",
        "The Tokenizer is just used to feed input to the LLM model. Sometimes, apart from the tokens, the model needs additional information like special tokens, attention masks, etc etc, so we can wrap our Tokenizer in a Wrapper as follows:"
      ],
      "metadata": {
        "id": "Mt9O8yxNo2Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers &> /dev/null"
      ],
      "metadata": {
        "id": "LPHHqfM1pSqU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the wrapper class"
      ],
      "metadata": {
        "id": "nEUY06t9qJIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "pt_tokenizer = PreTrainedTokenizerFast(tokenizer_file = 'hopper.json',\n",
        "                                       unk_token = '[UNK]',\n",
        "                                       pad_token = '[PAD]',\n",
        "                                       model_input_names = ['input_ids', 'token_type_ids', 'attention_mask']\n",
        "                                       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "47402c9f103945e79d138d6db77b4dbc",
            "1ce74d1b09af4c97b33ef81ddc613d65",
            "552d84d7e0464cd2b5865e8b36a1e286",
            "6d9df86a88ac4dc4ae54d29c610dc269",
            "c9785044f3a8490f8159441b53af59c5",
            "a7d5a98e1d1b4ab8a3491968e7fbf4b1",
            "4a7fa8c48bc945abb156042c03405818",
            "94c8afcb9d8f4caeac55e2e35d182df0",
            "b3388158cce549afb80e604f26c65b44",
            "b1f1a064c9824f9d91766f8b15530b0b",
            "45a4274950f6470da2e959a4eeb91038"
          ]
        },
        "id": "o82cAhh-peoa",
        "outputId": "1d2e7e02-97f6-4ecd-fb2e-3793b83c12d5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47402c9f103945e79d138d6db77b4dbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode for a single line"
      ],
      "metadata": {
        "id": "ajHZiNl3qNPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = pt_tokenizer(text)\n",
        "\n",
        "# now these can be passed to our LLM model directly\n",
        "pprint(model_inputs, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49vYjjSUp3Ba",
        "outputId": "12f7e65d-9017-455b-feb4-9916aac8f586"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            " 'input_ids': [267, 953, 333, 228, 2531, 138, 203, 154, 53, 95, 21, 459, 14, 64,\n",
            "               203, 384],\n",
            " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do it for a pair of lines"
      ],
      "metadata": {
        "id": "FWidKO2JqPRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = pt_tokenizer(text, text_pair = pair)\n",
        "\n",
        "# now these can be passed to our LLM model directly\n",
        "pprint(model_inputs, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmfrnyZXqLpl",
        "outputId": "e5939141-cb98-49fe-eedf-bc7e994f12a5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1],\n",
            " 'input_ids': [267, 953, 333, 228, 2531, 138, 203, 154, 53, 95, 21, 459, 14, 64,\n",
            "               203, 384, 211, 247, 46, 487, 412, 138, 257, 9],\n",
            " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "                    1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Processing\n",
        "We can also pass a batch of samples as input and it works!"
      ],
      "metadata": {
        "id": "KJxLQnhWqe87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_text = ['I like the book The Psychology of Money', \"I enjoyed watching the Transformers movie\", \"Oh! thanks for this\"]\n",
        "\n",
        "model_inputs = pt_tokenizer(batch_text)\n",
        "pprint(model_inputs, compact=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH-AJmQ7qlVy",
        "outputId": "45770d45-ddc1-46a2-cbd4-b325c758beda"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1],\n",
            "                    [1, 1, 1, 1, 1]],\n",
            " 'input_ids': [[54, 281, 131, 1701, 131, 19478, 153, 1564],\n",
            "               [54, 4096, 1443, 131, 7744, 307, 3760],\n",
            "               [772, 9, 1767, 200, 254]],\n",
            " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0],\n",
            "                    [0, 0, 0, 0, 0]]}\n"
          ]
        }
      ]
    }
  ]
}